{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Define the class mapping\n",
    "class_mapping = {\n",
    "    0: \"Healthy\",\n",
    "    1: \"Common Rust\",\n",
    "    2: \"Blight\",\n",
    "    3: \"Gray Leaf Spot\"\n",
    "}\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Info:\")\n",
    "print(train_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nClass distribution:\")\n",
    "print(train_df['Label'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_df, x='Label')\n",
    "plt.title('Distribution of Leaf Disease Classes')\n",
    "plt.xlabel('Disease Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(range(4), [class_mapping[i] for i in range(4)], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check image directory\n",
    "train_path = 'data/train'\n",
    "image_files = os.listdir(train_path)\n",
    "print(f\"\\nNumber of images in {train_path}: {len(image_files)}\")\n",
    "print(\"Sample image names:\", sorted(image_files)[:5])\n",
    "\n",
    "# Load and display a sample image\n",
    "sample_img_path = os.path.join(train_path, image_files[0])\n",
    "sample_img = Image.open(sample_img_path)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(sample_img)\n",
    "plt.title(f\"Sample Image\\nSize: {sample_img.size}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution with proper labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = train_df['Label'].value_counts()\n",
    "\n",
    "# Create bar plot\n",
    "sns.barplot(x=class_counts.index.map(class_mapping), y=class_counts.values)\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Distribution of Maize Leaf Disease Classes', fontsize=12, pad=20)\n",
    "plt.xlabel('Disease Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print percentage distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "for label, count in class_counts.items():\n",
    "    percentage = (count/len(train_df))*100\n",
    "    print(f\"{class_mapping[label]}: {count} images ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaizeLeafDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.leaf_data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.leaf_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = f\"{self.leaf_data.iloc[idx]['Image']}.jpg\"\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        # Load and convert image to RGB\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.leaf_data.iloc[idx]['Label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Test the dataset\n",
    "def test_dataset():\n",
    "    # Simple transform for testing\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Create a test dataset\n",
    "    test_dataset = MaizeLeafDataset(\n",
    "        csv_file='train.csv',\n",
    "        img_dir='data/train',\n",
    "        transform=test_transform\n",
    "    )\n",
    "    \n",
    "    # Get a sample\n",
    "    image, label = test_dataset[0]\n",
    "    \n",
    "    print(f\"Image tensor shape: {image.shape}\")\n",
    "    print(f\"Label: {label} ({class_mapping[label]})\")\n",
    "    \n",
    "    # Visualize the transformed image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image.permute(1, 2, 0))  # Convert from CxHxW to HxWxC for display\n",
    "    plt.title(f\"Transformed Image\\nLabel: {class_mapping[label]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Run the test\n",
    "test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for training and validation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = MaizeLeafDataset(\n",
    "    csv_file='train.csv',\n",
    "    img_dir='data/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# Split into train and validation\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Test the data loaders\n",
    "def test_data_loaders():\n",
    "    # Get a batch of training data\n",
    "    images, labels = next(iter(train_loader))\n",
    "    \n",
    "    print(\"Training Data:\")\n",
    "    print(f\"Batch image shape: {images.shape}\")\n",
    "    print(f\"Batch label shape: {labels.shape}\")\n",
    "    print(f\"Sample labels: {labels[:5]}\")\n",
    "    print(f\"Sample labels mapped: {[class_mapping[label.item()] for label in labels[:5]]}\")\n",
    "    \n",
    "    # Display a grid of images from the batch\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    grid_size = min(4, images.size(0))\n",
    "    for i in range(grid_size):\n",
    "        plt.subplot(1, grid_size, i + 1)\n",
    "        # Denormalize the images for display\n",
    "        img = images[i].permute(1, 2, 0)\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{class_mapping[labels[i].item()]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDataloader sizes:\")\n",
    "    print(f\"Training batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Run the test\n",
    "test_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # Add fixed seed\n",
    ")\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinMaizeClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4, model_name='swin_base_patch4_window7_224'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load base model\n",
    "        self.model = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=0,\n",
    "            global_pool=''\n",
    "        )\n",
    "        \n",
    "        # Get number of features\n",
    "        n_features = self.model.num_features\n",
    "        \n",
    "        # Create custom classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get features from Swin\n",
    "        x = self.model.forward_features(x)  # [B, H, W, C]\n",
    "        print(f\"Shape after forward_features: {x.shape}\")\n",
    "        \n",
    "        # Global average pooling over both spatial dimensions\n",
    "        x = x.mean(dim=[1, 2])  # Take mean over both H and W dimensions\n",
    "        print(f\"Shape after mean pooling: {x.shape}\")\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        print(f\"Shape after classifier: {x.shape}\")\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Test the model\n",
    "def test_fixed_model():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create model instance\n",
    "    model = SwinMaizeClassifier().to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    images, labels = next(iter(train_loader))\n",
    "    images = images.to(device)\n",
    "    \n",
    "    print(f\"\\nInput image shape: {images.shape}\")\n",
    "    \n",
    "    # Do a forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    \n",
    "    print(f\"\\nFinal output shape: {outputs.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    \n",
    "    # Test if output matches expected shape\n",
    "    assert outputs.shape == torch.Size([images.shape[0], 4]), \\\n",
    "        f\"Expected output shape [{images.shape[0]}, 4] but got {outputs.shape}\"\n",
    "    \n",
    "    # Print sample predictions\n",
    "    print(\"\\nSample predictions:\")\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f\"Predictions: {predicted[:5]}\")\n",
    "    print(f\"Actual labels: {labels[:5]}\")\n",
    "    \n",
    "    # Print prediction probabilities\n",
    "    print(\"\\nPrediction probabilities for first sample:\")\n",
    "    print(probs[0])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run the test\n",
    "model = test_fixed_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = next(model.parameters()).device\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=num_epochs,\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # Training metrics\n",
    "    best_val_f1 = 0.0\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    val_f1_scores = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Collect predictions for F1 score\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_predictions.extend(predicted.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            if batch_idx % 20 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                      f'Step [{batch_idx}/{len(train_loader)}], '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Calculate training F1 score\n",
    "        train_f1 = f1_score(\n",
    "            np.array(train_labels), \n",
    "            np.array(train_predictions), \n",
    "            average='weighted'\n",
    "        ) * 100\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Collect predictions for F1 score\n",
    "                val_predictions.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_f1 = f1_score(\n",
    "            np.array(val_labels), \n",
    "            np.array(val_predictions), \n",
    "            average='weighted'\n",
    "        ) * 100\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        \n",
    "        print(f'\\nEpoch [{epoch+1}/{num_epochs}]:')\n",
    "        print(f'Training Loss: {epoch_loss:.4f}')\n",
    "        print(f'Training F1 Score: {train_f1:.2f}%')\n",
    "        print(f'Validation Loss: {epoch_val_loss:.4f}')\n",
    "        print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        print(f'Validation F1 Score: {val_f1:.2f}%')\n",
    "        \n",
    "        # Calculate per-class F1 scores for validation set\n",
    "        per_class_f1 = f1_score(\n",
    "            np.array(val_labels), \n",
    "            np.array(val_predictions), \n",
    "            average=None\n",
    "        ) * 100\n",
    "        \n",
    "        print(\"\\nPer-class Validation F1 Scores:\")\n",
    "        for i, class_f1 in enumerate(per_class_f1):\n",
    "            print(f\"{class_mapping[i]}: {class_f1:.2f}%\")\n",
    "        \n",
    "        # Save best model based on F1 score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'val_f1_score': val_f1,\n",
    "                'per_class_f1': per_class_f1.tolist(),\n",
    "            }, 'best_swin_model.pth')\n",
    "            print(f'\\nBest model saved with F1 Score: {best_val_f1:.2f}%')\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(train_losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(val_f1_scores)\n",
    "    plt.title('Validation F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return train_losses, val_accuracies, val_f1_scores\n",
    "\n",
    "# Start training\n",
    "train_losses, val_accuracies, val_f1_scores = train_model(model, train_loader, val_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_raw_confusion_matrix(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Generate and plot raw confusion matrix showing actual counts\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize lists to store predictions and true labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Class mapping for labels\n",
    "    class_mapping = {\n",
    "        0: \"Healthy\",\n",
    "        1: \"Common Rust\",\n",
    "        2: \"Blight\",\n",
    "        3: \"Gray Leaf Spot\"\n",
    "    }\n",
    "    \n",
    "    # Collect predictions\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm, \n",
    "                annot=True,           # Show numbers in cells\n",
    "                fmt='d',              # Use integer format\n",
    "                cmap='Blues',         # Use Blues colormap\n",
    "                xticklabels=[class_mapping[i] for i in range(4)],\n",
    "                yticklabels=[class_mapping[i] for i in range(4)])\n",
    "    \n",
    "    plt.title('Confusion Matrix (Raw Counts)')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print actual confusion matrix values\n",
    "    print(\"\\nConfusion Matrix (Raw Counts):\")\n",
    "    print(\"\\nTrue Labels (rows) vs Predicted Labels (columns):\")\n",
    "    print(\"\\nPredicted:\")\n",
    "    print(\"         \", end=\"\")\n",
    "    for i in range(4):\n",
    "        print(f\"{class_mapping[i]:<15}\", end=\"\")\n",
    "    print(\"\\nActual\")\n",
    "    for i in range(4):\n",
    "        print(f\"{class_mapping[i]:<9}\", end=\"\")\n",
    "        for j in range(4):\n",
    "            print(f\"{cm[i,j]:<15}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "# Load and run confusion matrix analysis\n",
    "def run_confusion_matrix_analysis():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SwinMaizeClassifier().to(device)\n",
    "    checkpoint = torch.load('best_swin_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    plot_raw_confusion_matrix(model, val_loader, device)\n",
    "\n",
    "# Run the analysis\n",
    "run_confusion_matrix_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set(model_path='best_swin_model.pth'):\n",
    "    # Set up device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the best model\n",
    "    model = SwinMaizeClassifier().to(device)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Test transform (same as validation, no augmentation)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Get test files\n",
    "    test_files = sorted(os.listdir('data/test'), \n",
    "                       key=lambda x: int(x.split('.')[0]))\n",
    "    predictions = []\n",
    "    confidence_scores = []\n",
    "    \n",
    "    print(f\"Processing {len(test_files)} test images...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_name in tqdm(test_files, desc=\"Predicting\"):\n",
    "            # Load and preprocess image\n",
    "            img_path = os.path.join('data/test', img_name)\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = test_transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Make prediction\n",
    "            outputs = model(image)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probs, 1)\n",
    "            \n",
    "            predictions.append(predicted.item())\n",
    "            confidence_scores.append(confidence.item())\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Image': range(len(predictions)),\n",
    "        'Label': predictions\n",
    "    })\n",
    "    \n",
    "    # Print prediction distribution\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for label, count in pd.Series(predictions).value_counts().items():\n",
    "        percentage = (count/len(predictions))*100\n",
    "        print(f\"{class_mapping[label]}: {count} images ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Print confidence statistics\n",
    "    confidence_array = np.array(confidence_scores)\n",
    "    print(\"\\nConfidence Statistics:\")\n",
    "    print(f\"Mean confidence: {confidence_array.mean():.4f}\")\n",
    "    print(f\"Min confidence: {confidence_array.min():.4f}\")\n",
    "    print(f\"Max confidence: {confidence_array.max():.4f}\")\n",
    "    \n",
    "    # Save predictions\n",
    "    submission_df.to_csv('swin_submissionFinal.csv', index=False)\n",
    "    print(\"\\nPredictions saved to 'swin_submission.csv'\")\n",
    "    \n",
    "    return submission_df, confidence_scores\n",
    "\n",
    "# Run predictions\n",
    "from tqdm import tqdm\n",
    "submission_df, confidence_scores = predict_test_set()\n",
    "\n",
    "# Visualize confidence distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(confidence_scores, bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Prediction Confidence')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(n_samples=5):\n",
    "    # Load some test images\n",
    "    test_files = sorted(os.listdir('data/test'), \n",
    "                       key=lambda x: int(x.split('.')[0]))\n",
    "    \n",
    "    # Get same transform as used in prediction\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SwinMaizeClassifier().to(device)\n",
    "    checkpoint = torch.load('best_swin_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(n_samples):\n",
    "            # Load and show original image\n",
    "            img_path = os.path.join('data/test', test_files[i])\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Get prediction\n",
    "            img_tensor = test_transform(img).unsqueeze(0).to(device)\n",
    "            outputs = model(img_tensor)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probs, 1)\n",
    "            \n",
    "            # Plot\n",
    "            plt.subplot(1, n_samples, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Pred: {class_mapping[predicted.item()]}\\nConf: {confidence.item():.4f}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_predictions(n_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(model, train_loader, val_loader, n_trials=20):\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning using a grid search approach\n",
    "    \"\"\"\n",
    "    # Define hyperparameter search space\n",
    "    lr_space = [1e-5, 3e-5, 1e-4, 3e-4, 1e-3]\n",
    "    weight_decay_space = [0.001, 0.01, 0.1]\n",
    "    dropout_space = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    batch_size_space = [8, 16, 32]\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_params = None\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Initialize results tracking\n",
    "    results = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Randomly sample hyperparameters\n",
    "        lr = np.random.choice(lr_space)\n",
    "        weight_decay = np.random.choice(weight_decay_space)\n",
    "        dropout = np.random.choice(dropout_space)\n",
    "        \n",
    "        print(f\"\\nTrial {trial + 1}/{n_trials}\")\n",
    "        print(f\"Parameters: lr={lr}, weight_decay={weight_decay}, dropout={dropout}\")\n",
    "        \n",
    "        # Update model dropout\n",
    "        for layer in model.modules():\n",
    "            if isinstance(layer, nn.Dropout):\n",
    "                layer.p = dropout\n",
    "        \n",
    "        # Initialize optimizer and scheduler\n",
    "        optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            betas=(0.9, 0.999)\n",
    "        )\n",
    "        \n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=5,  # Reduced epochs for tuning\n",
    "            eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Mini training loop for evaluation\n",
    "        for epoch in range(5):  # Reduced epochs for tuning\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f'Epoch [{epoch+1}/5], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            epoch_val_loss = val_loss / len(val_loader)\n",
    "            val_accuracy = 100 * correct / total\n",
    "            \n",
    "            print(f'\\nEpoch [{epoch+1}/5]:')\n",
    "            print(f'Training Loss: {epoch_loss:.4f}')\n",
    "            print(f'Validation Loss: {epoch_val_loss:.4f}')\n",
    "            print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "            \n",
    "            scheduler.step()\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'lr': lr,\n",
    "            'weight_decay': weight_decay,\n",
    "            'dropout': dropout,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'train_loss': epoch_loss,\n",
    "            'val_loss': epoch_val_loss\n",
    "        })\n",
    "        \n",
    "        # Update best parameters if needed\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            best_params = {\n",
    "                'lr': lr,\n",
    "                'weight_decay': weight_decay,\n",
    "                'dropout': dropout\n",
    "            }\n",
    "            \n",
    "            # Save best model state during tuning\n",
    "            torch.save({\n",
    "                'trial': trial,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'best_params': best_params,\n",
    "                'val_accuracy': best_val_acc,\n",
    "            }, 'best_tuned_model.pth')\n",
    "    \n",
    "    # Convert results to DataFrame for analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Visualize hyperparameter effects\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Learning rate vs Validation Accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.boxplot(x='lr', y='val_accuracy', data=results_df)\n",
    "    plt.title('Learning Rate vs Validation Accuracy')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Weight decay vs Validation Accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.boxplot(x='weight_decay', y='val_accuracy', data=results_df)\n",
    "    plt.title('Weight Decay vs Validation Accuracy')\n",
    "    \n",
    "    # Dropout vs Validation Accuracy\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.boxplot(x='dropout', y='val_accuracy', data=results_df)\n",
    "    plt.title('Dropout vs Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(f\"Learning Rate: {best_params['lr']}\")\n",
    "    print(f\"Weight Decay: {best_params['weight_decay']}\")\n",
    "    print(f\"Dropout: {best_params['dropout']}\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return best_params, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyperparameter_tuning():\n",
    "    # Initialize model\n",
    "    model = SwinMaizeClassifier()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Run hyperparameter tuning\n",
    "    best_params, results_df = tune_hyperparameters(model, train_loader, val_loader, n_trials=10)\n",
    "    \n",
    "    # Save tuning results\n",
    "    results_df.to_csv('hyperparameter_tuning_results.csv', index=False)\n",
    "    \n",
    "    return best_params, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, results_df = run_hyperparameter_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
